# -*- coding: utf-8 -*-
"""Forecasting Hidroelétrica Ensemble Optimize.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AUH7g8BeI1FlogxcsKFsq3smcYzQq5Sm
"""

!pip install catboost
!pip install shap

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
import lightgbm as lgb
import xgboost as xgb
from catboost import CatBoostRegressor, Pool
import shap

# ==========================================
# 1. FEATURE ENGINEERING
# ==========================================

def create_time_features(df, date_col='data'):
    """
    Cria features temporais a partir da data
    """
    df = df.copy()
    df['dia_semana'] = df[date_col].dt.dayofweek
    df['dia_mes'] = df[date_col].dt.day
    df['mes'] = df[date_col].dt.month
    df['trimestre'] = df[date_col].dt.quarter
    df['dia_ano'] = df[date_col].dt.dayofyear
    df['semana_ano'] = df[date_col].dt.isocalendar().week
    df['fim_semana'] = (df['dia_semana'] >= 5).astype(int)

    # Features cíclicas (importante para capturar sazonalidade)
    df['mes_sin'] = np.sin(2 * np.pi * df['mes'] / 12)
    df['mes_cos'] = np.cos(2 * np.pi * df['mes'] / 12)
    df['dia_ano_sin'] = np.sin(2 * np.pi * df['dia_ano'] / 365)
    df['dia_ano_cos'] = np.cos(2 * np.pi * df['dia_ano'] / 365)

    return df


def create_lag_features(df, target_col='geracao_mw', lags=[1, 2, 3, 7, 14, 30]):
    """
    Cria features de lag (valores passados)
    """
    df = df.copy()
    for lag in lags:
        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)
    return df


def create_rolling_features(df, target_col='geracao_mw', windows=[7, 14, 30]):
    """
    Cria features de médias móveis e estatísticas
    """
    df = df.copy()
    for window in windows:
        df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(window=window).mean()
        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window=window).std()
        df[f'{target_col}_rolling_min_{window}'] = df[target_col].rolling(window=window).min()
        df[f'{target_col}_rolling_max_{window}'] = df[target_col].rolling(window=window).max()
    return df


def create_external_features(df, feature_cols):
    """
    Cria lags e rolling para variáveis externas (vazão, precipitação, etc)
    """
    df = df.copy()
    for col in feature_cols:
        # Lags para variáveis externas
        for lag in [1, 3, 7]:
            df[f'{col}_lag_{lag}'] = df[col].shift(lag)

        # Rolling para variáveis externas
        for window in [7, 14]:
            df[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()

    return df


def prepare_features(df, target_col='geracao_mw',
                    external_cols=['vazao_afluente', 'precipitacao', 'nivel_reservatorio'],
                    forecast_horizon=7):
    """
    Pipeline completo de feature engineering
    """
    df = df.copy()

    # Features temporais
    df = create_time_features(df)

    # Lags do target
    df = create_lag_features(df, target_col)

    # Rolling statistics
    df = create_rolling_features(df, target_col)

    # Features de variáveis externas
    if external_cols:
        df = create_external_features(df, external_cols)

    # Criar target para forecast_horizon dias à frente
    df[f'{target_col}_target'] = df[target_col].shift(-forecast_horizon)

    # Remover NaN criados pelos lags e rolling
    df = df.dropna()

    return df


# ==========================================
# 2. PREPARAÇÃO DOS DADOS
# ==========================================

def split_train_test(df, target_col='geracao_mw_target', test_size=0.2):
    """
    Split temporal dos dados
    """
    # Identificar features (todas exceto target e data)
    feature_cols = [col for col in df.columns if col not in [target_col, 'data', 'geracao_mw']]

    X = df[feature_cols]
    y = df[target_col]

    # Split temporal
    split_idx = int(len(X) * (1 - test_size))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]

    return X_train, X_test, y_train, y_test, feature_cols


# ==========================================
# 3. MODELOS INDIVIDUAIS
# ==========================================

def train_lightgbm(X_train, y_train, X_val, y_val, params=None):
    """
    Treina modelo LightGBM
    """
    if params is None:
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'max_depth': -1,
            'min_child_samples': 20,
            'verbose': -1
        }

    train_data = lgb.Dataset(X_train, label=y_train)
    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

    model = lgb.train(
        params,
        train_data,
        num_boost_round=1000,
        valid_sets=[train_data, val_data],
        valid_names=['train', 'valid'],
        callbacks=[
            lgb.early_stopping(stopping_rounds=50),
            lgb.log_evaluation(period=100)
        ]
    )

    return model


def train_xgboost(X_train, y_train, X_val, y_val, params=None):
    """
    Treina modelo XGBoost
    """
    if params is None:
        params = {
            'objective': 'reg:squarederror',
            'eval_metric': 'rmse',
            'learning_rate': 0.05,
            'max_depth': 6,
            'min_child_weight': 3,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'tree_method': 'hist',
            'verbosity': 0
        }

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dval = xgb.DMatrix(X_val, label=y_val)

    evals = [(dtrain, 'train'), (dval, 'valid')]

    model = xgb.train(
        params,
        dtrain,
        num_boost_round=1000,
        evals=evals,
        early_stopping_rounds=50,
        verbose_eval=100
    )

    return model


def train_catboost(X_train, y_train, X_val, y_val, params=None):
    """
    Treina modelo CatBoost
    """
    if params is None:
        params = {
            'iterations': 1000,
            'learning_rate': 0.05,
            'depth': 6,
            'l2_leaf_reg': 3,
            'loss_function': 'RMSE',
            'eval_metric': 'RMSE',
            'early_stopping_rounds': 50,
            'verbose': 100,
            'random_seed': 42
        }

    train_pool = Pool(X_train, y_train)
    val_pool = Pool(X_val, y_val)

    model = CatBoostRegressor(**params)
    model.fit(train_pool, eval_set=val_pool, verbose=100)

    return model


# ==========================================
# 4. ENSEMBLE DE MODELOS
# ==========================================

class EnsembleModel:
    """
    Ensemble combinando LightGBM, XGBoost e CatBoost
    """

    def __init__(self, weights=None):
        """
        Args:
            weights: pesos para cada modelo [lgb, xgb, cat]
                    Se None, usa média simples
        """
        self.lgb_model = None
        self.xgb_model = None
        self.cat_model = None
        self.weights = weights if weights else [1/3, 1/3, 1/3]

    def train(self, X_train, y_train, X_val, y_val):
        """
        Treina os três modelos
        """
        print("\n" + "="*60)
        print("TREINANDO ENSEMBLE DE MODELOS")
        print("="*60)

        # LightGBM
        print("\n[1/3] Treinando LightGBM...")
        self.lgb_model = train_lightgbm(X_train, y_train, X_val, y_val)

        # XGBoost
        print("\n[2/3] Treinando XGBoost...")
        self.xgb_model = train_xgboost(X_train, y_train, X_val, y_val)

        # CatBoost
        print("\n[3/3] Treinando CatBoost...")
        self.cat_model = train_catboost(X_train, y_train, X_val, y_val)

        print("\n✓ Ensemble treinado com sucesso!")

    def predict(self, X):
        """
        Predição usando ensemble ponderado
        """
        # Predições individuais
        pred_lgb = self.lgb_model.predict(X, num_iteration=self.lgb_model.best_iteration)

        if isinstance(X, pd.DataFrame):
            pred_xgb = self.xgb_model.predict(xgb.DMatrix(X))
        else:
            pred_xgb = self.xgb_model.predict(xgb.DMatrix(X))

        pred_cat = self.cat_model.predict(X)

        # Ensemble ponderado
        ensemble_pred = (self.weights[0] * pred_lgb +
                        self.weights[1] * pred_xgb +
                        self.weights[2] * pred_cat)

        return ensemble_pred, pred_lgb, pred_xgb, pred_cat

    def optimize_weights(self, X_val, y_val):
        """
        Otimiza pesos do ensemble usando validação
        """
        from scipy.optimize import minimize

        def objective(weights):
            pred, pred_lgb, pred_xgb, pred_cat = self.predict_with_weights(X_val, weights)
            return mean_squared_error(y_val, pred)

        # Restrições: pesos somam 1 e são positivos
        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
        bounds = [(0, 1)] * 3

        result = minimize(objective,
                         x0=self.weights,
                         method='SLSQP',
                         bounds=bounds,
                         constraints=constraints)

        self.weights = result.x
        print(f"\nPesos otimizados: LGB={self.weights[0]:.3f}, XGB={self.weights[1]:.3f}, CAT={self.weights[2]:.3f}")

    def predict_with_weights(self, X, weights):
        """
        Predição com pesos específicos
        """
        pred_lgb = self.lgb_model.predict(X, num_iteration=self.lgb_model.best_iteration)
        pred_xgb = self.xgb_model.predict(xgb.DMatrix(X))
        pred_cat = self.cat_model.predict(X)

        ensemble_pred = (weights[0] * pred_lgb +
                        weights[1] * pred_xgb +
                        weights[2] * pred_cat)

        return ensemble_pred, pred_lgb, pred_xgb, pred_cat


# ==========================================
# 5. AVALIAÇÃO COMPLETA
# ==========================================

def evaluate_ensemble(ensemble, X_test, y_test):
    """
    Avalia ensemble e modelos individuais
    """
    print("\n" + "="*60)
    print("AVALIAÇÃO DO ENSEMBLE")
    print("="*60)

    # Predições
    pred_ensemble, pred_lgb, pred_xgb, pred_cat = ensemble.predict(X_test)

    results = {}

    # Avaliar cada modelo
    for name, pred in [('Ensemble', pred_ensemble),
                       ('LightGBM', pred_lgb),
                       ('XGBoost', pred_xgb),
                       ('CatBoost', pred_cat)]:
        mae = mean_absolute_error(y_test, pred)
        rmse = np.sqrt(mean_squared_error(y_test, pred))
        r2 = r2_score(y_test, pred)
        mape = np.mean(np.abs((y_test - pred) / y_test)) * 100

        results[name] = {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mape': mape,
            'predictions': pred
        }

        print(f"\n{name}:")
        print(f"  MAE:  {mae:.2f} MW")
        print(f"  RMSE: {rmse:.2f} MW")
        print(f"  R²:   {r2:.4f}")
        print(f"  MAPE: {mape:.2f}%")

    return results


def plot_ensemble_comparison(y_test, results):
    """
    Compara performance dos modelos
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    models = ['Ensemble', 'LightGBM', 'XGBoost', 'CatBoost']
    colors = ['green', 'blue', 'red', 'orange']

    # Plot 1: Séries temporais
    ax = axes[0, 0]
    ax.plot(y_test.values, label='Real', linewidth=2.5, color='black', alpha=0.7)
    for model, color in zip(models, colors):
        ax.plot(results[model]['predictions'], label=model,
               linewidth=1.5, alpha=0.7, color=color)
    ax.set_xlabel('Tempo')
    ax.set_ylabel('Geração (MW)')
    ax.set_title('Previsões: Comparação entre Modelos')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Plot 2: Métricas comparativas (barras)
    ax = axes[0, 1]
    metrics_names = ['MAE', 'RMSE', 'MAPE']
    x = np.arange(len(metrics_names))
    width = 0.2

    for i, model in enumerate(models):
        values = [results[model]['mae'],
                 results[model]['rmse'],
                 results[model]['mape']]
        ax.bar(x + i*width, values, width, label=model, color=colors[i], alpha=0.8)

    ax.set_xlabel('Métricas')
    ax.set_ylabel('Valor')
    ax.set_title('Comparação de Métricas')
    ax.set_xticks(x + width * 1.5)
    ax.set_xticklabels(metrics_names)
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')

    # Plot 3: R² Score
    ax = axes[1, 0]
    r2_scores = [results[model]['r2'] for model in models]
    bars = ax.bar(models, r2_scores, color=colors, alpha=0.8)
    ax.set_ylabel('R² Score')
    ax.set_title('R² Score - Comparação')
    ax.set_ylim([min(r2_scores) - 0.01, 1.0])
    ax.grid(True, alpha=0.3, axis='y')

    # Adicionar valores nas barras
    for bar, score in zip(bars, r2_scores):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{score:.4f}', ha='center', va='bottom', fontweight='bold')

    # Plot 4: Scatter do Ensemble
    ax = axes[1, 1]
    ax.scatter(y_test, results['Ensemble']['predictions'],
              alpha=0.5, color='green', edgecolors='darkgreen')
    ax.plot([y_test.min(), y_test.max()],
           [y_test.min(), y_test.max()],
           'r--', linewidth=2, label='Perfeito')
    ax.set_xlabel('Valor Real (MW)')
    ax.set_ylabel('Valor Previsto (MW)')
    ax.set_title('Scatter Plot: Ensemble')
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()


def plot_residuals_comparison(y_test, results):
    """
    Compara resíduos dos modelos
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))

    models = ['Ensemble', 'LightGBM', 'XGBoost', 'CatBoost']
    colors = ['green', 'blue', 'red', 'orange']

    for ax, model, color in zip(axes.ravel(), models, colors):
        residuals = y_test.values - results[model]['predictions']

        ax.hist(residuals, bins=50, edgecolor='black', alpha=0.7, color=color)
        ax.axvline(0, color='red', linestyle='--', linewidth=2)
        ax.set_xlabel('Resíduo (MW)')
        ax.set_ylabel('Frequência')
        ax.set_title(f'Distribuição dos Resíduos - {model}')
        ax.grid(True, alpha=0.3)

        # Adicionar estatísticas
        mean_res = np.mean(residuals)
        std_res = np.std(residuals)
        ax.text(0.02, 0.98, f'μ = {mean_res:.2f}\nσ = {std_res:.2f}',
               transform=ax.transAxes, va='top',
               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.show()


# ==========================================
# 6. ANÁLISE SHAP DO ENSEMBLE
# ==========================================

def analyze_shap_ensemble(ensemble, X_train, X_test, feature_names, max_display=20):
    """
    Análise SHAP para os 3 modelos do ensemble
    """
    print("\n" + "="*60)
    print("ANÁLISE SHAP - ENSEMBLE")
    print("="*60)

    # SHAP para LightGBM
    print("\n[1/3] Calculando SHAP para LightGBM...")
    explainer_lgb = shap.TreeExplainer(ensemble.lgb_model)
    shap_values_lgb = explainer_lgb.shap_values(X_test)

    # SHAP para XGBoost
    print("[2/3] Calculando SHAP para XGBoost...")
    explainer_xgb = shap.TreeExplainer(ensemble.xgb_model)
    shap_values_xgb = explainer_xgb.shap_values(X_test)

    # SHAP para CatBoost
    print("[3/3] Calculando SHAP para CatBoost...")
    explainer_cat = shap.TreeExplainer(ensemble.cat_model)
    shap_values_cat = explainer_cat.shap_values(X_test)

    # SHAP do Ensemble (média ponderada)
    shap_values_ensemble = (ensemble.weights[0] * shap_values_lgb +
                           ensemble.weights[1] * shap_values_xgb +
                           ensemble.weights[2] * shap_values_cat)

    # Plot comparativo de importância
    fig, axes = plt.subplots(2, 2, figsize=(18, 14))

    # Ensemble
    plt.sca(axes[0, 0])
    shap.summary_plot(shap_values_ensemble, X_test, max_display=max_display, show=False)
    axes[0, 0].set_title('SHAP - Ensemble', fontsize=14, fontweight='bold')

    # LightGBM
    plt.sca(axes[0, 1])
    shap.summary_plot(shap_values_lgb, X_test, max_display=max_display, show=False)
    axes[0, 1].set_title('SHAP - LightGBM', fontsize=14, fontweight='bold')

    # XGBoost
    plt.sca(axes[1, 0])
    shap.summary_plot(shap_values_xgb, X_test, max_display=max_display, show=False)
    axes[1, 0].set_title('SHAP - XGBoost', fontsize=14, fontweight='bold')

    # CatBoost
    plt.sca(axes[1, 1])
    shap.summary_plot(shap_values_cat, X_test, max_display=max_display, show=False)
    axes[1, 1].set_title('SHAP - CatBoost', fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.show()

    # Bar plot comparativo
    fig, axes = plt.subplots(1, 4, figsize=(20, 6))

    for ax, shap_vals, title in zip(axes,
                                     [shap_values_ensemble, shap_values_lgb, shap_values_xgb, shap_values_cat],
                                     ['Ensemble', 'LightGBM', 'XGBoost', 'CatBoost']):
        plt.sca(ax)
        shap.summary_plot(shap_vals, X_test, plot_type="bar", max_display=15, show=False)
        ax.set_title(f'Importância - {title}', fontsize=12, fontweight='bold')

    plt.tight_layout()
    plt.show()

    return shap_values_ensemble, explainer_lgb


# ==========================================
# 7. EXEMPLO DE USO COMPLETO
# ==========================================

def exemplo_completo():
    """
    Pipeline completo com Ensemble
    """
    print("="*60)
    print("FORECASTING HIDRELÉTRICO - ENSEMBLE (LGB+XGB+CAT)")
    print("="*60)

    # Simular dados
    np.random.seed(42)
    dates = pd.date_range('2020-01-01', '2023-12-31', freq='D')
    df = pd.DataFrame({
        'data': dates,
        'geracao_mw': np.sin(np.arange(len(dates)) * 2 * np.pi / 365) * 500 + 2000 + np.random.randn(len(dates)) * 100,
        'vazao_afluente': np.sin(np.arange(len(dates)) * 2 * np.pi / 365) * 50 + 300 + np.random.randn(len(dates)) * 20,
        'precipitacao': np.maximum(0, np.random.randn(len(dates)) * 10 + 50),
        'nivel_reservatorio': 100 + np.random.randn(len(dates)) * 2
    })

    FORECAST_HORIZON = 7

    # Feature Engineering
    print("\n[1/5] Feature Engineering...")
    df_features = prepare_features(df, forecast_horizon=FORECAST_HORIZON)
    print(f"Features criadas: {df_features.shape[1]} colunas")

    # Split
    print("\n[2/5] Split Train/Test...")
    X_train, X_test, y_train, y_test, feature_cols = split_train_test(df_features)
    print(f"Train: {X_train.shape[0]} | Test: {X_test.shape[0]}")

    # Treinar Ensemble
    print("\n[3/5] Treinando Ensemble...")
    ensemble = EnsembleModel()
    ensemble.train(X_train, y_train, X_test, y_test)

    # Otimizar pesos (opcional)
    print("\n[4/5] Otimizando pesos do Ensemble...")
    ensemble.optimize_weights(X_test, y_test)

    # Avaliar
    print("\n[5/5] Avaliação...")
    results = evaluate_ensemble(ensemble, X_test, y_test)

    # Visualizações
    print("\nGerando visualizações...")
    plot_ensemble_comparison(y_test, results)
    plot_residuals_comparison(y_test, results)

    # SHAP
    print("\nAnálise SHAP...")
    shap_values, explainer = analyze_shap_ensemble(ensemble, X_train, X_test, feature_cols)

    # Salvar modelos
    ensemble.lgb_model.save_model('ensemble_lightgbm.txt')
    ensemble.xgb_model.save_model('ensemble_xgboost.json')
    ensemble.cat_model.save_model('ensemble_catboost.cbm')
    print("\n✓ Modelos salvos!")

    print("\n" + "="*60)
    print("PIPELINE CONCLUÍDO COM SUCESSO!")
    print("="*60)

    return ensemble, df_features, results


if __name__ == "__main__":
    ensemble, df, results = exemplo_completo()

"""```markdown
# Previsão de Geração Hidrelétrica com Ensemble de Modelos (LightGBM, XGBoost, CatBoost)

## Visão Geral

Este projeto demonstra a construção de um pipeline completo para previsão da geração de energia hidrelétrica (em MW) utilizando um ensemble de modelos de Machine Learning (LightGBM, XGBoost e CatBoost). O objetivo é prever a geração com um horizonte de `X` dias à frente, incorporando engenharia de features temporais, lags e estatísticas móveis, além de análise de interpretabilidade com SHAP.

## Funcionalidades

- **Engenharia de Features:** Criação de features temporais (dia da semana, mês, etc.), lags do target, estatísticas móveis (médias, desvios) e features de variáveis externas (vazão, precipitação, nível de reservatório).
- **Split Temporal:** Divisão dos dados em treino e teste respeitando a ordem temporal para simular um cenário real de previsão.
- **Modelos Individuais:** Treinamento e avaliação de LightGBM, XGBoost e CatBoost Regressors.
- **Ensemble Ponderado:** Combinação das previsões dos modelos individuais através de uma média ponderada, com otimização dos pesos para melhorar a performance.
- **Avaliação Detalhada:** Cálculo de métricas de erro (MAE, RMSE, R², MAPE) para o ensemble e para cada modelo individual.
- **Visualizações:** Gráficos comparativos de previsões, métricas, resíduos e scatter plots para análise da qualidade das previsões.
- **Análise SHAP:** Interpretabilidade dos modelos utilizando SHAP (SHapley Additive exPlanations) para entender a importância e o impacto de cada feature nas previsões do ensemble e dos modelos individuais.
- **Salvamento de Modelos:** Persistência dos modelos treinados para uso futuro.

## Estrutura do Projeto

O código é organizado em funções modulares para facilitar a reutilização e manutenção:

- `create_time_features()`: Cria features baseadas na data.
- `create_lag_features()`: Cria features de lags do target.
- `create_rolling_features()`: Cria features de estatísticas móveis.
- `create_external_features()`: Cria lags e rolling para variáveis externas.
- `prepare_features()`: Pipeline completo de engenharia de features.
- `split_train_test()`: Realiza o split temporal dos dados.
- `train_lightgbm()`, `train_xgboost()`, `train_catboost()`: Funções para treinamento dos modelos individuais.
- `EnsembleModel` (Classe): Implementa o ensemble com métodos `train()`, `predict()` e `optimize_weights()`.
- `evaluate_ensemble()`: Avalia o desempenho do ensemble e dos modelos individuais.
- `plot_ensemble_comparison()`, `plot_residuals_comparison()`: Funções de visualização.
- `analyze_shap_ensemble()`: Realiza a análise SHAP para o ensemble.
- `exemplo_completo()`: Função que orquestra todo o pipeline (simulação de dados, engenharia de features, treinamento, otimização, avaliação e SHAP).

## Instalação

Certifique-se de ter as seguintes bibliotecas instaladas. Você pode instalá-las via pip:

```bash
pip install numpy pandas matplotlib seaborn scikit-learn lightgbm xgboost catboost shap
```

## Uso

Para executar o pipeline completo e ver um exemplo prático, basta chamar a função `exemplo_completo()`.

```python
if __name__ == "__main__":
    ensemble, df, results = exemplo_completo()
```

### Parâmetros Configuráveis (dentro de `exemplo_completo()`):

- `FORECAST_HORIZON`: Número de dias à frente que se deseja prever (padrão: 7).
- Parâmetros dos modelos individuais (`train_lightgbm`, `train_xgboost`, `train_catboost`).

## Avaliação dos Modelos

O pipeline imprime as métricas de avaliação (MAE, RMSE, R², MAPE) para o ensemble e para cada modelo individual, permitindo uma comparação direta do desempenho.

### Exemplo de Resultados (simulados)

```
Ensemble:
  MAE:  81.16 MW
  RMSE: 99.49 MW
  R²:   0.9239
  MAPE: 4.37%

LightGBM:
  MAE:  82.40 MW
  RMSE: 102.77 MW
  R²:   0.9188
  MAPE: 4.47%

XGBoost:
  MAE:  82.89 MW
  RMSE: 101.09 MW
  R²:   0.9214
  MAPE: 4.47%

CatBoost:
  MAE:  81.43 MW
  RMSE: 100.67 MW
  R²:   0.9221
  MAPE: 4.37%
```

## Análise SHAP

Após a avaliação, a função `analyze_shap_ensemble` gera plots de resumo SHAP para o ensemble e cada modelo, visualizando a importância e o impacto das features nas previsões.

## Modelos Salvos

Os modelos treinados (LightGBM, XGBoost, CatBoost) são salvos nos formatos `txt`, `json` e `cbm` respectivamente, permitindo o carregamento e uso posterior para novas previsões.

```
ensemble_lightgbm.txt
ensemble_xgboost.json
ensemble_catboost.cbm
```

## Contribuições

Contribuições são bem-vindas! Sinta-se à vontade para abrir issues ou pull requests.

## Licença

Este projeto está licenciado sob a licença MIT. Veja o arquivo `LICENSE` para mais detalhes.
```

### 1. Engenharia de Features (Feature Engineering)

Esta seção é crucial para transformar os dados brutos em um formato que os modelos de Machine Learning possam aprender. São criadas diversas variáveis a partir da coluna de data (`data`) e do valor alvo (`geracao_mw`), bem como de variáveis externas.

*   **`create_time_features(df, date_col='data')`**
    *   **Propósito:** Extrair informações de tempo diretamente da coluna de data.
    *   **Funcionalidade:** Cria colunas como `dia_semana`, `dia_mes`, `mes`, `trimestre`, `dia_ano`, `semana_ano`, e `fim_semana`. Além disso, gera *features cíclicas* (`mes_sin`, `mes_cos`, `dia_ano_sin`, `dia_ano_cos`) que são importantes para capturar a sazonalidade sem quebrar a ordem ordinal dos meses/dias (por exemplo, dezembro e janeiro são adjacentes sazonalmente).

*   **`create_lag_features(df, target_col='geracao_mw', lags=[1, 2, 3, 7, 14, 30])`**
    *   **Propósito:** Adicionar valores passados da variável alvo como novas features.
    *   **Funcionalidade:** Cria colunas como `geracao_mw_lag_1`, `geracao_mw_lag_7`, etc. Os lags representam a geração de dias anteriores, o que é fundamental para prever séries temporais, pois o valor atual geralmente depende do passado próximo.

*   **`create_rolling_features(df, target_col='geracao_mw', windows=[7, 14, 30])`**
    *   **Propósito:** Criar estatísticas móveis da variável alvo.
    *   **Funcionalidade:** Calcula médias móveis (`_rolling_mean_`), desvios padrão (`_rolling_std_`), valores mínimos (`_rolling_min_`) e máximos (`_rolling_max_`) para diferentes janelas de tempo (e.g., 7, 14, 30 dias). Essas features ajudam o modelo a entender tendências e a volatilidade recente.

*   **`create_external_features(df, feature_cols)`**
    *   **Propósito:** Aplicar engenharia de features (lags e rolling) a variáveis externas, como vazão, precipitação ou nível de reservatório.
    *   **Funcionalidade:** Similar às funções anteriores, mas aplicada a `feature_cols` específicas. Isso permite que o modelo capture a influência de variáveis ambientais ou operacionais no passado.

*   **`prepare_features(df, target_col='geracao_mw', external_cols=['vazao_afluente', 'precipitacao', 'nivel_reservatorio'], forecast_horizon=7)`**
    *   **Propósito:** Orquestrar todas as funções de engenharia de features em um único pipeline e definir o target para a previsão.
    *   **Funcionalidade:** Chama sequencialmente as funções `create_time_features`, `create_lag_features`, `create_rolling_features` e `create_external_features`. Finalmente, cria a coluna alvo (`geracao_mw_target`) deslocando a coluna `geracao_mw` para trás pelo `forecast_horizon`. Isso significa que o modelo será treinado para prever a geração `forecast_horizon` dias no futuro. A função também remove linhas com valores `NaN` que surgem devido à criação de lags e rolling features.

### 2. Preparação dos Dados

Esta seção lida com a divisão dos dados em conjuntos de treinamento e teste, garantindo que a ordem temporal seja preservada para simular um cenário de previsão realista.

*   **`split_train_test(df, target_col='geracao_mw_target', test_size=0.2)`**
    *   **Propósito:** Dividir o DataFrame em conjuntos de treino e teste de forma temporal, o que é crucial para séries temporais.
    *   **Funcionalidade:** Primeiramente, identifica as colunas que serão usadas como features (todas exceto a coluna alvo, a data original e a geração original). Em seguida, separa as features (`X`) do target (`y`). O split é feito de forma sequencial, onde `test_size` (padrão de 0.2, ou 20%) dos dados mais recentes são reservados para teste, enquanto o restante é usado para treinamento. Isso simula como um modelo seria usado na prática: treinado com dados passados e testado em dados futuros.

### 3. Modelos Individuais

Esta seção define as funções para treinar cada um dos modelos de *gradient boosting* que serão utilizados no ensemble. Cada função configura o modelo com parâmetros padrão e utiliza *early stopping* para evitar *overfitting*.

*   **`train_lightgbm(X_train, y_train, X_val, y_val, params=None)`**
    *   **Propósito:** Treinar um modelo LightGBM para regressão.
    *   **Funcionalidade:** Inicializa um `lgb.Dataset` para os dados de treino e validação. O modelo é treinado usando `lgb.train` com parâmetros padrão (`objective='regression'`, `metric='rmse'`, `boosting_type='gbdt'`, etc.) que podem ser sobrescritos. Utiliza *early stopping* com `stopping_rounds=50`, o que significa que o treinamento será interrompido se a métrica de validação não melhorar por 50 iterações consecutivas, salvando a melhor iteração.

*   **`train_xgboost(X_train, y_train, X_val, y_val, params=None)`**
    *   **Propósito:** Treinar um modelo XGBoost para regressão.
    *   **Funcionalidade:** Converte os dados para o formato `xgb.DMatrix`, que é o formato otimizado do XGBoost. O treinamento é realizado com `xgb.train` utilizando parâmetros padrão (`objective='reg:squarederror'`, `eval_metric='rmse'`, etc.) configuráveis. Assim como o LightGBM, emprega *early stopping* de 50 rodadas para otimizar o desempenho e evitar *overfitting*.

*   **`train_catboost(X_train, y_train, X_val, y_val, params=None)`**
    *   **Propósito:** Treinar um modelo CatBoost para regressão.
    *   **Funcionalidade:** Cria `Pool` objects para os dados de treino e validação, que é o formato de dados do CatBoost. O modelo é instanciado como `CatBoostRegressor` com parâmetros padrão (`iterations=1000`, `learning_rate=0.05`, `loss_function='RMSE'`, etc.) que podem ser personalizados. Também utiliza *early stopping* com `early_stopping_rounds=50` para interromper o treinamento se a performance no conjunto de validação não melhorar.

### 4. Ensemble de Modelos

Esta seção implementa a classe `EnsembleModel`, que coordena o treinamento e a combinação das previsões dos modelos LightGBM, XGBoost e CatBoost.

*   **`EnsembleModel.__init__(self, weights=None)`**
    *   **Propósito:** Inicializar o modelo de ensemble.
    *   **Funcionalidade:** O construtor define os modelos individuais (inicialmente `None`) e os pesos que serão usados para combinar suas previsões. Se nenhum peso for fornecido, ele usa uma média simples (pesos iguais para cada modelo).

*   **`EnsembleModel.train(self, X_train, y_train, X_val, y_val)`**
    *   **Propósito:** Treinar cada um dos modelos individuais que compõem o ensemble.
    *   **Funcionalidade:** Chama as funções de treinamento (`train_lightgbm`, `train_xgboost`, `train_catboost`) para cada um dos três modelos, passando os dados de treino e validação. Isso garante que cada componente do ensemble seja devidamente ajustado aos dados.

*   **`EnsembleModel.predict(self, X)`**
    *   **Propósito:** Gerar previsões usando o ensemble ponderado.
    *   **Funcionalidade:** Para cada modelo treinado, ele gera uma previsão. Em seguida, combina essas previsões individuais usando os pesos definidos no `__init__` ou otimizados, resultando em uma previsão final do ensemble. Ele também retorna as previsões de cada modelo individual.

*   **`EnsembleModel.optimize_weights(self, X_val, y_val)`**
    *   **Propósito:** Ajustar os pesos do ensemble para minimizar um erro (neste caso, `mean_squared_error`) no conjunto de validação.
    *   **Funcionalidade:** Utiliza a função `minimize` da biblioteca `scipy.optimize` para encontrar a combinação ideal de pesos para LightGBM, XGBoost e CatBoost. Os pesos são otimizados para que a previsão do ensemble tenha o menor erro possível no conjunto de validação, respeitando a restrição de que a soma dos pesos deve ser 1 e cada peso deve ser positivo (entre 0 e 1). Após a otimização, os pesos internos do ensemble são atualizados.

### 5. Avaliação Completa

Esta seção é dedicada à avaliação do desempenho do ensemble e dos modelos individuais, utilizando métricas padrão de regressão e visualizações comparativas.

*   **`evaluate_ensemble(ensemble, X_test, y_test)`**
    *   **Propósito:** Calcular métricas de erro para o ensemble e para cada modelo individual.
    *   **Funcionalidade:** Primeiramente, obtém as previsões de todos os modelos (ensemble, LightGBM, XGBoost, CatBoost) sobre o conjunto de teste (`X_test`). Em seguida, calcula diversas métricas de avaliação para cada um: Erro Médio Absoluto (MAE), Raiz do Erro Quadrático Médio (RMSE), Coeficiente de Determinação (R²) e Erro Percentual Absoluto Médio (MAPE). Esses resultados são armazenados em um dicionário e impressos para comparação.

*   **`plot_ensemble_comparison(y_test, results)`**
    *   **Propósito:** Visualizar e comparar as previsões do ensemble e dos modelos individuais com os valores reais.
    *   **Funcionalidade:** Gera uma série de gráficos para análise visual:
        *   **Séries temporais:** Plota os valores reais de `y_test` junto com as previsões de cada modelo ao longo do tempo, permitindo observar como cada um se comporta.
        *   **Métricas comparativas:** Exibe as métricas MAE, RMSE e MAPE em um gráfico de barras, facilitando a comparação direta do desempenho.
        *   **R² Score:** Apresenta os valores de R² em outro gráfico de barras, destacando a proporção da variância na variável dependente que é previsível a partir das variáveis independentes.
        *   **Scatter Plot do Ensemble:** Um gráfico de dispersão que compara os valores reais com os previstos pelo ensemble, idealmente formando uma linha diagonal (`y=x`), indicando previsões perfeitas.

*   **`plot_residuals_comparison(y_test, results)`**
    *   **Propósito:** Analisar a distribuição dos resíduos (erros de previsão) de cada modelo.
    *   **Funcionalidade:** Para cada modelo (ensemble e individuais), calcula os resíduos (diferença entre valor real e previsto) e gera um histograma de sua distribuição. Isso ajuda a entender se os erros são aleatórios, viesados ou se possuem um padrão, e se estão normalmente distribuídos (indicando um bom ajuste do modelo).

### 6. Análise SHAP do Ensemble

Esta seção foca na interpretabilidade dos modelos utilizando SHAP (SHapley Additive exPlanations), uma técnica popular para explicar a saída de qualquer modelo de machine learning.

*   **`analyze_shap_ensemble(ensemble, X_train, X_test, feature_names, max_display=20)`**
    *   **Propósito:** Calcular e visualizar os valores SHAP para cada modelo individual e para o ensemble, revelando a importância e o impacto das features.
    *   **Funcionalidade:**
        1.  **Calcula SHAP Individual:** Para cada modelo (LightGBM, XGBoost, CatBoost) dentro do ensemble, é instanciado um `shap.TreeExplainer` para calcular os valores SHAP no conjunto de teste (`X_test`). Os valores SHAP indicam a contribuição de cada feature para a previsão individual de cada amostra.
        2.  **Calcula SHAP do Ensemble:** Os valores SHAP do ensemble são obtidos pela média ponderada dos valores SHAP de cada modelo individual, utilizando os pesos otimizados do ensemble. Isso nos dá uma visão unificada da importância das features para a previsão combinada.
        3.  **Visualização (Summary Plots):** Gera múltiplos *summary plots* (resumo de gráficos) da biblioteca SHAP:
            *   **Bee Swarm Plots:** Apresenta a distribuição dos valores SHAP para as features mais importantes, mostrando como cada feature impacta a previsão para diferentes amostras (cores indicam o valor da feature, e a posição horizontal, o impacto).
            *   **Bar Plots:** Exibe a importância média absoluta de cada feature, ordenando-as da mais à menos influente. Isso permite uma comparação rápida entre a importância das features para o ensemble e para cada modelo individual.
        *   **Benefício:** Esta análise é fundamental para entender `o porquê` de um modelo tomar certas decisões. Ela ajuda a identificar as features mais relevantes para a previsão de geração hidrelétrica e a comparar como diferentes modelos utilizam essas features.

### 7. Exemplo de Uso Completo

Esta seção orquestra todas as etapas do pipeline de previsão, desde a simulação de dados até o salvamento dos modelos, passando por engenharia de features, treinamento, otimização, avaliação e análise de interpretabilidade.

*   **`exemplo_completo()`**
    *   **Propósito:** Demonstrar um fluxo de trabalho completo para a previsão de geração hidrelétrica usando o ensemble de modelos.
    *   **Funcionalidade:**
        1.  **Simulação de Dados:** Inicia criando um conjunto de dados sintéticos (`df`) que simula a geração hidrelétrica, vazão afluente, precipitação e nível de reservatório ao longo do tempo. Isso permite que o pipeline seja testado de forma autônoma.
        2.  **Engenharia de Features:** Chama a função `prepare_features` para aplicar todas as transformações e criações de features temporais, de lag e rolling. Define o `FORECAST_HORIZON` (horizonte de previsão).
        3.  **Split Train/Test:** Divide os dados preparados em conjuntos de treinamento e teste de forma temporal, utilizando a função `split_train_test`.
        4.  **Treinamento do Ensemble:** Instancia a classe `EnsembleModel` e chama seu método `train` para treinar os modelos LightGBM, XGBoost e CatBoost nos dados de treinamento e validação.
        5.  **Otimização de Pesos:** (Opcional, mas recomendado) Chama o método `optimize_weights` do ensemble para ajustar os pesos de combinação dos modelos, buscando a melhor performance no conjunto de validação.
        6.  **Avaliação:** Utiliza a função `evaluate_ensemble` para calcular e exibir métricas de desempenho para o ensemble e para cada modelo individual no conjunto de teste.
        7.  **Visualizações:** Gera os gráficos comparativos de previsões e resíduos através das funções `plot_ensemble_comparison` e `plot_residuals_comparison`.
        8.  **Análise SHAP:** Realiza a análise de interpretabilidade com SHAP, utilizando a função `analyze_shap_ensemble`, e gera os plots correspondentes.
        9.  **Salvamento de Modelos:** Salva os modelos treinados (LightGBM, XGBoost, CatBoost) em seus respectivos formatos de arquivo, permitindo que sejam carregados e usados posteriormente sem a necessidade de retreinamento.
    *   **Retorno:** A função retorna o objeto `ensemble` treinado, o `DataFrame` com as features e os `results` da avaliação, o que permite acesso posterior para análises ou previsões.
"""